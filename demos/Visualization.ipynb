{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import cudf\n",
    "import cugraph\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, clean and featurize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_day(day, month, year, day_of_week):\n",
    "    for i, _ in enumerate(zip(day, month, year)):\n",
    "        d = day[i]\n",
    "        shift = month[i] if month[i] < 3 else 0\n",
    "        m = month[i] + shift + 1\n",
    "        y = year[i] - (month[i] < 3) - 2000\n",
    "        day_of_week[i] = int((math.floor(2.6 * m) + (d + y - 35) + (y // 4)) % 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    df['hour'] = df['pickup_datetime'].dt.hour\n",
    "    df['year'] = df['pickup_datetime'].dt.year\n",
    "    df['month'] = df['pickup_datetime'].dt.month\n",
    "    df['day'] = df['pickup_datetime'].dt.day\n",
    "    df['diff'] = df['dropoff_datetime'].astype('int64') - df['pickup_datetime'].astype('int64')\n",
    "\n",
    "    df = df.apply_rows(\n",
    "        week_day,\n",
    "        incols=['day', 'month', 'year'], \n",
    "        outcols={'day_of_week': np.int32},\n",
    "        kwargs={}\n",
    "    )\n",
    "\n",
    "    df = df.drop(\n",
    "        columns=[\n",
    "            'pickup_datetime',\n",
    "            'dropoff_datetime'\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dtypes = OrderedDict(\n",
    "    [\n",
    "        ('vendor_id', 'int32'),\n",
    "        ('pickup_datetime', 'date'),\n",
    "        ('dropoff_datetime', 'date'),\n",
    "        ('passenger_count', 'int32'),\n",
    "        ('trip_distance', 'int32'),\n",
    "        ('pickup_longitude', 'float64'),\n",
    "        ('pickup_latitude', 'float64'),\n",
    "        ('rate_code', 'int32'),\n",
    "        ('store_and_fwd_flag', 'int32'),\n",
    "        ('dropoff_longitude', 'float64'),\n",
    "        ('dropoff_latitude', 'float64'),\n",
    "        ('payment_type', 'int32'),\n",
    "        ('fare_amount', 'float64'),\n",
    "        ('extra', 'float64'),\n",
    "        ('mta_tax', 'float64'),\n",
    "        ('tip_amount', 'float64'),\n",
    "        ('tolls_amount', 'float64'),\n",
    "        ('surcharge', 'float64'),\n",
    "        ('total_amount', 'float64')\n",
    "    ]\n",
    ")\n",
    "\n",
    "use_col  = [\n",
    "    'pickup_datetime',\n",
    "    'dropoff_datetime',\n",
    "    'passenger_count', \n",
    "    'pickup_longitude',\n",
    "    'pickup_latitude',     \n",
    "    'dropoff_longitude',\n",
    "    'dropoff_latitude'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyctaxi_months = range(1, 13)\n",
    "nyctaxi_dir = 's3://bsql/data/nytaxi/yellow/2016'\n",
    "nyctaxi_files = [f'{nyctaxi_dir}/yellow_tripdata_2016-{month:02}.csv' for month in nyctaxi_months]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    cudf.read_csv(\n",
    "        nyctaxi_file,\n",
    "        names=list(columns_dtypes.keys()),\n",
    "        dtype=list(columns_dtypes.values()),\n",
    "        skip_rows=1,\n",
    "        usecols=use_col,\n",
    "        storage_options={'anon': True}\n",
    "    )\n",
    "for nyctaxi_file in nyctaxi_files]\n",
    "\n",
    "taxi_df = cudf.concat(data)\n",
    "del data  # clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Raw number of rows: {len(taxi_df):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out records with missing or outlier values\n",
    "query_frags = (\n",
    "    \"(passenger_count > 0 and passenger_count < 6) \" +\n",
    "    \"and (pickup_longitude > -75 and pickup_longitude < -73) \" +\n",
    "    \"and (dropoff_longitude > -75 and dropoff_longitude < -73) \" +\n",
    "    \"and (pickup_latitude > 40 and pickup_latitude < 42) \" +\n",
    "    \"and (dropoff_latitude > 40 and dropoff_latitude < 42)\" +\n",
    "    \"and (pickup_latitude  != dropoff_latitude) \" +     # remove data where pickup location and drop-off the same\n",
    "    \"and (pickup_longitude != dropoff_longitude)\"       # remove data where pickup location and drop-off the same\n",
    ")\n",
    "\n",
    "taxi_df = taxi_df.query(query_frags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df = add_features(taxi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Filtered number of rows: {len(taxi_df):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and analyzing graph\n",
    "## Create list of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [\n",
    "    taxi_df[['pickup_longitude', 'pickup_latitude']].drop_duplicates().rename(columns={'pickup_longitude': 'long', 'pickup_latitude': 'lat'}),\n",
    "    taxi_df[['dropoff_longitude', 'dropoff_latitude']].drop_duplicates().rename(columns={'dropoff_longitude': 'long', 'dropoff_latitude': 'lat'})\n",
    "]\n",
    "\n",
    "nodes = cudf.concat(nodes).drop_duplicates().reset_index(drop=True).reset_index().rename(columns={'index': 'id'})\n",
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of geo points in the dataset: {0:,}'.format(len(nodes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = (\n",
    "    taxi_df[['pickup_longitude', 'pickup_latitude','dropoff_longitude', 'dropoff_latitude']]\n",
    "    .drop_duplicates()\n",
    "    .rename(columns={'pickup_longitude': 'long', 'pickup_latitude': 'lat'})\n",
    "    .merge(nodes, on=['lat', 'long'])\n",
    "    .rename(columns={'long': 'pickup_longitude', 'lat': 'pickup_latitude', 'id': 'pickup_id', 'dropoff_longitude': 'long', 'dropoff_latitude': 'lat'})\n",
    "    .merge(nodes, on=['lat', 'long'])\n",
    "    .rename(columns={'long': 'dropoff_longitude', 'lat': 'dropoff_latitude', 'id': 'dropoff_id'})\n",
    ")[['pickup_id', 'dropoff_id']]\n",
    "\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = cugraph.from_cudf_edgelist(\n",
    "    edges,\n",
    "    source='pickup_id',\n",
    "    destination='dropoff_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del nodes\n",
    "del edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph distribution of degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "g.degree().to_pandas()['degree'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = cugraph.pagerank(g, alpha=.85, max_iter=1000, tol=1.0e-05)\n",
    "page.sort_values(by='pagerank', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cugraph.jaccard(g)\n",
    "df.sort_values(by='jaccard_coeff', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}